{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa6aa950",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78c1267c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# find .env automagically by walking up directories until it's found\n",
    "dotenv_path = find_dotenv()\n",
    "project_dir = Path(dotenv_path).parent\n",
    "\n",
    "# load up the entries as environment variables\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a4ce65",
   "metadata": {},
   "source": [
    "# Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d2c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir = project_dir/'data/raw/render_results'\n",
    "\n",
    "syms_dirs = list(raw_data_dir.glob('simulacao*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f52ddf5",
   "metadata": {},
   "source": [
    "# Create HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec0cd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ctc_das/Desktop/part_counting/data/raw/render_results/simulacao245/simulacao245_0032.png')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_dir = np.random.choice(syms_dirs)\n",
    "img_fpath = np.random.choice(list(sym_dir.glob('*.png')))\n",
    "img_fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44390c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image of size 512x512, with 4 channels.\n",
       "Use numpy.asarray to access buffer data."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = o3d.io.read_image(str(img_fpath))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75e3fb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"single_render.hdf5\" (mode r+)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_fpath = project_dir/'data/interim/single_render.hdf5'\n",
    "\n",
    "# TODO: explore chunking (see https://docs.h5py.org/en/stable/high/file.html#chunk-cache\n",
    "# and https://portal.hdfgroup.org/display/HDF5/Chunking+in+HDF5)\n",
    "# it may be useful for keeping the hdf5 in HDD\n",
    "h = h5py.File(str(h5_fpath), \"w\")\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a5dfab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 512, 512)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# swap axis so that channels is the first axis\n",
    "data = np.moveaxis(np.array(img)[:,:,1:3], -1, 0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1a6d294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'245_0032'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_name = img_fpath.name.replace('.png','').replace('simulacao','')\n",
    "dset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce65001b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"245_0032\": shape (2, 512, 512), type \"|u1\">"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.create_dataset(dset_name, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e2836d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dba35b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "526336"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_fpath.stat().st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8cc5cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392919"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_fpath.stat().st_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b5e3e",
   "metadata": {},
   "source": [
    "So it adds some header to the data, as expected as it drops the png compression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca9e16f",
   "metadata": {},
   "source": [
    "# Create HDF5 with multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b82bcf29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sym_dir = np.random.choice(syms_dirs)\n",
    "img_fpaths = np.random.choice(list(raw_data_dir.glob('*/*.png')), 1010, replace=False)\n",
    "len(np.unique(img_fpaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "dddef474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399427682"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_size = sum([img_fpath.stat().st_size for img_fpath in img_fpaths])\n",
    "imgs_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f8584ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529909264"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_fpath = project_dir/'data/interim/multiple_renders.hdf5'\n",
    "\n",
    "with h5py.File(str(h5_fpath), \"w\") as h:\n",
    "    for img_fpath in img_fpaths:\n",
    "        img = o3d.io.read_image(str(img_fpath))\n",
    "\n",
    "        data = np.moveaxis(np.array(img)[:,:,1:3], -1, 0)\n",
    "\n",
    "        dset_name = img_fpath.name.replace('.png','').replace('simulacao','')\n",
    "\n",
    "        h.create_dataset(dset_name, data=data)\n",
    "\n",
    "h5_size = h5_fpath.stat().st_size\n",
    "h5_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e351c972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32667135474100667"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(h5_size - imgs_size) / imgs_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e139b0",
   "metadata": {},
   "source": [
    "# Reading speed comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5991e588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529909264"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_fpath = Path('/data/multiple_renders.hdf5')\n",
    "\n",
    "all_dsets = list()\n",
    "with h5py.File(str(h5_fpath), \"w\") as h:\n",
    "    for img_fpath in img_fpaths:\n",
    "        img = o3d.io.read_image(str(img_fpath))\n",
    "\n",
    "        data = np.moveaxis(np.array(img)[:,:,1:3], -1, 0)\n",
    "\n",
    "        dset_name = img_fpath.name.replace('.png','').replace('simulacao','')\n",
    "        all_dsets.append(dset_name)\n",
    "\n",
    "        h.create_dataset(dset_name, data=data)\n",
    "\n",
    "h5_size = h5_fpath.stat().st_size\n",
    "h5_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9b6a55ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.38 s, sys: 83.4 ms, total: 5.47 s\n",
      "Wall time: 5.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for img_fpath in img_fpaths:\n",
    "    np.array(o3d.io.read_image(str(img_fpath)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "29d1d8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 100 ms, sys: 75.2 ms, total: 176 ms\n",
      "Wall time: 175 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with h5py.File(h5_fpath, 'r') as h:\n",
    "    for dset_name in all_dsets:\n",
    "        d = h[dset_name][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "40661b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 261 ms, sys: 83.3 ms, total: 345 ms\n",
      "Wall time: 344 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for dset_name in all_dsets:\n",
    "    with h5py.File(h5_fpath, 'r') as h:\n",
    "        d = h[dset_name][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bbe645",
   "metadata": {},
   "source": [
    "So HDF5 is a lot faster than png, which is expected as it doesn't compress the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5eaeceb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284132486"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_h5_fpath = Path('/data/multiple_renders_compressed.hdf5')\n",
    "\n",
    "with h5py.File(str(compressed_h5_fpath), \"w\") as h:\n",
    "    for img_fpath in img_fpaths:\n",
    "        img = o3d.io.read_image(str(img_fpath))\n",
    "\n",
    "        data = np.moveaxis(np.array(img)[:,:,1:3], -1, 0)\n",
    "\n",
    "        dset_name = img_fpath.name.replace('.png','').replace('simulacao','')\n",
    "\n",
    "        h.create_dataset(dset_name, data=data, compression='gzip')\n",
    "\n",
    "compressed_h5_size = compressed_h5_fpath.stat().st_size\n",
    "compressed_h5_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5e9e31a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.69 s, sys: 54.7 ms, total: 2.74 s\n",
      "Wall time: 2.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for dset_name in all_dsets:\n",
    "    with h5py.File(compressed_h5_fpath, 'r') as h:\n",
    "        d = h[dset_name][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e80fc7",
   "metadata": {},
   "source": [
    "Yet, even with a better compression than the pngs it is still significantly faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b082b466",
   "metadata": {},
   "source": [
    "# Test multiple images in dataset\n",
    "\n",
    "Also chunkable and resizable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "dd82f61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syms_dirs_sample = np.random.choice(syms_dirs, 10)\n",
    "len(syms_dirs_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d3574305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399693722"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_size = sum([img_fpath.stat().st_size for sym_dir in syms_dirs_sample for img_fpath in sym_dir.glob('*.png')])\n",
    "imgs_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "155d69bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529628328"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_fpath = Path('/data/single_dataset.hdf5')\n",
    "\n",
    "with h5py.File(str(h5_fpath), \"w\") as h:\n",
    "    dset = h.create_dataset(\n",
    "        'renders',\n",
    "        (len(syms_dirs_sample),101,2,512,512),\n",
    "        dtype='uint8',\n",
    "        chunks=(1,1,2,512,512),\n",
    "    )\n",
    "    for i, sym_dir in enumerate(syms_dirs_sample):\n",
    "        for img_fpath in sym_dir.glob('*.png'):\n",
    "            img = o3d.io.read_image(str(img_fpath))\n",
    "\n",
    "            data = np.moveaxis(np.array(img)[:,:,1:3], -1, 0)\n",
    "\n",
    "            data_i = int(img_fpath.name.replace('.png','').split('_')[-1])\n",
    "\n",
    "            dset[i,data_i,:,:,:] = data\n",
    "\n",
    "h5_size = h5_fpath.stat().st_size\n",
    "h5_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "49bf4f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 308 ms, sys: 59.1 ms, total: 368 ms\n",
      "Wall time: 367 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(len(syms_dirs_sample)):\n",
    "    for j in range(101):\n",
    "        with h5py.File(h5_fpath, 'r') as h:\n",
    "            d = h['renders']\n",
    "            d[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "92c8ff65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.16 s, sys: 0 ns, total: 6.16 s\n",
      "Wall time: 8.61 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "529628328"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "h5_fpath = Path('/data/single_dataset_resizable.hdf5')\n",
    "\n",
    "with h5py.File(str(h5_fpath), \"w\") as h:\n",
    "    dset = h.create_dataset(\n",
    "        'renders',\n",
    "        (0,101,2,512,512),\n",
    "        maxshape=(None,101,2,512,512),\n",
    "        dtype='uint8',\n",
    "        chunks=(1,1,2,512,512),\n",
    "    )\n",
    "    for i, sym_dir in enumerate(syms_dirs_sample):\n",
    "        dset.resize(i+1,axis=0)\n",
    "        for img_fpath in sym_dir.glob('*.png'):\n",
    "            img = o3d.io.read_image(str(img_fpath))\n",
    "\n",
    "            data = np.moveaxis(np.array(img)[:,:,1:3], -1, 0)\n",
    "\n",
    "            data_i = int(img_fpath.name.replace('.png','').split('_')[-1])\n",
    "\n",
    "            dset[i,data_i,:,:,:] = data\n",
    "\n",
    "h5_size = h5_fpath.stat().st_size\n",
    "h5_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "af360af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 363 ms, sys: 0 ns, total: 363 ms\n",
      "Wall time: 363 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(len(syms_dirs_sample)):\n",
    "    for j in range(101):\n",
    "        with h5py.File(h5_fpath, 'r') as h:\n",
    "            d = h['renders']\n",
    "            d[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "55532608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 375 ms, sys: 0 ns, total: 375 ms\n",
      "Wall time: 374 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(len(syms_dirs_sample)):\n",
    "    for j in range(101):\n",
    "        with h5py.File(project_dir/'data/interim/single_dataset_resizable.hdf5', 'r') as h:\n",
    "            d = h['renders']\n",
    "            d[i,j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9c09c",
   "metadata": {},
   "source": [
    "## With compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "eae87127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282874222"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_fpath = Path('/data/compressed_chunked_dataset.hdf5')\n",
    "\n",
    "with h5py.File(str(h5_fpath), \"w\") as h:\n",
    "    dset = h.create_dataset(\n",
    "        'renders',\n",
    "        (len(syms_dirs_sample),101,2,512,512),\n",
    "        dtype='uint8',\n",
    "        chunks=(1,1,2,512,512),\n",
    "        compression='gzip',\n",
    "    )\n",
    "    for i, sym_dir in enumerate(syms_dirs_sample):\n",
    "        for img_fpath in sym_dir.glob('*.png'):\n",
    "            img = o3d.io.read_image(str(img_fpath))\n",
    "\n",
    "            data = np.moveaxis(np.array(img)[:,:,1:3], -1, 0)\n",
    "\n",
    "            data_i = int(img_fpath.name.replace('.png','').split('_')[-1])\n",
    "\n",
    "            dset[i,data_i,:,:,:] = data\n",
    "\n",
    "h5_size = h5_fpath.stat().st_size\n",
    "h5_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "bb097249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.3 s, sys: 0 ns, total: 2.3 s\n",
      "Wall time: 2.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(len(syms_dirs_sample)):\n",
    "    for j in range(101):\n",
    "        with h5py.File(h5_fpath, 'r') as h:\n",
    "            d = h['renders']\n",
    "            d[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "5c5dd51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.32 s, sys: 0 ns, total: 2.32 s\n",
      "Wall time: 2.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(len(syms_dirs_sample)):\n",
    "    for j in range(101):\n",
    "        with h5py.File(project_dir/'data/interim/compressed_chunked_dataset.hdf5', 'r') as h:\n",
    "            d = h['renders']\n",
    "            d[i,j]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:part_counting]",
   "language": "python",
   "name": "conda-env-part_counting-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
